{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Role Models: A Recommendation System for Skill Training and Study\n",
    "\n",
    "__Gwen Rathgeber | [GitHub](https://github.com/gwenrathgeber) | [LinkedIn](https://www.linkedin.com/in/gwenrathgeber/)__  \n",
    "\n",
    "\n",
    "_Special thanks to [Uthgar](https://twitter.com/Dr_Uthgar) at Mobalytics.gg for suggesting this project_ \n",
    "\n",
    "\n",
    "_The accompanying Flask app to this project can be viewed at https://github.com/gwenrathgeber/lol_role_models_app_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "League of Legends is a Multiplayer Online Battle Arena game known for attracting devoted players with a strong competitive drive. As one of the earliest games to popularize online video game streaming on platforms such as Twitch.tv, League demonstrated the appeal of not only playing games, but watching others compete. Due to the complexity of the game, a highly effective method of improving is studying the gameplay of higher-skilled players. We wish to improve this process for players by providing a recommendation system which matches players with Role Models: high-ranking players whose playstyles are similar to the user. Users can then use other tools to watch replays of recent games played by their recommended Role Models, simplifying and enhancing the process of finding high-level games to study through personalization and filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "In order to implement the recommender, we require a body of high-level players who will be recommended to users. All necessary data will be acquired from the Riot Games API, which can provide match-level data for games played by on a given account.\n",
    "\n",
    "After scraping the data we need, we will need to combine each players' match history into a single row of aggregate statistics, using subject-matter knowledge to identify metrics which will be represent distinctive play patterns while also being comparable between lower- and higher-skilled players.\n",
    "\n",
    "Finally, we will implement the recommendation system itself, which will involve pulling an individual player's match history, performing our aggregation, and comparing their statistics against our Role Model candidates.\n",
    "\n",
    "Evaluation of this recommendation system is unfortunately limited to subjective interpretation of results by myself and test users, as it is not designed to drive a particular business objective or KPI. However, if a similar tool was deployed on one of the many stat-tracking and personal improvement websites which exist for League of Legends Players, some important target metrics would include the page bounce rate for the tool, churn and retention rates of tool users vs. non-users, and user feedback in the form of qualitative and quantitative satisfaction surveys that could be added to the results page. \n",
    "\n",
    "### Table of Contents\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Executive Summary](#Executive-Summary)\n",
    "- [Data Dictionary](#Data-Dictionary)\n",
    "- [API Scraping](#API-Scraping)\n",
    "- [Data Processing](#Data-Processing)\n",
    "- [Recommender](#Recommender)\n",
    "- [Future Work](#Future-Work)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "The following endpoints of the Riot API were used over the course of this project, please consult their documentation for details of the fields:\n",
    " - [Summoner by Account ID Endpoint](https://developer.riotgames.com/apis#summoner-v4/GET_getByAccountId)\n",
    " - [Summoner by Account Name Endpoint](https://developer.riotgames.com/apis#summoner-v4/GET_getBySummonerName)\n",
    " - [Challenger Leagues Endpoint](https://developer.riotgames.com/apis#league-v4/GET_getChallengerLeague)\n",
    " - [Match Histories Endpoint](https://developer.riotgames.com/apis#match-v4/GET_getMatchlist)\n",
    " - [Match Data Endpoint](https://developer.riotgames.com/apis#match-v4/GET_getMatch)\n",
    " - [Timeline Data Endpoint](https://developer.riotgames.com/apis#match-v4/GET_getMatchTimeline)\n",
    "\n",
    "The following is a representation of the custom fields we generated in our game data analysis:\n",
    "\n",
    "\n",
    "Column | Data Type| Description\n",
    "-|-|-\n",
    "csd_10 | float|Average CS (Creep Score) Difference Between Player and Opponent at 10 minutes\n",
    "gold_d_10 | float| Average Gold Difference Between Player and Opponent at 10 minutes\n",
    "xpd_10| float|Average Experience Difference Between Player and Opponent at 10 minutes\n",
    "dmg_share| float| Average Percent of Team's Total Damage to Champions Dealt by Player\n",
    "dmg_taken_share| float| Average Percent of Team's Total Damage Taken Received by Player\n",
    "vision_score| float| Average Vision Score of Player\n",
    "kill_participation|float|Average Percent of Team's Kills a Player was Involved In\n",
    "obj_dmg_share|float| Average Percent of Team's Total Damage to Epic Monsters and Structures by Player\n",
    "dragons|float|Average Percent of Dragons Taken by Player's Team\n",
    "barons|float|Average Percent of Barons Taken by Player's Team\n",
    "wards_cleared |float | Average Ratio of Wards Cleared to Wards Placed by Player\n",
    "vision_wards_purchased |float | Average Ratio of Vision Wards Purchased to Wards Placed by Player\n",
    "kda_early | float| Average Ratio of Kills + Deaths + Assists Occurring before 10 minutes\n",
    "kda_mid |float | Average Ratio of Kills + Deaths + Assists Occurring between 10 and 20 minutes\n",
    "kda_late |float| Average Ratio of Kills + Deaths + Assists Occurring after 20 minutes\n",
    "solo_kills |float | Average Ratio of Kills with no Assists by Teammates\n",
    "teamfight_kills |float | Average Ratio of Kills with two or more Assists by Teammates\n",
    "skirmish_kills |float | Average Ratio of Kills with only one Assist by Teammates\n",
    "wards_early |float | Average Ratio of Wards Placed before 10 minutes\n",
    "wards_mid |float |  Average Ratio of Wards Placed between 10 and 20 minutes\n",
    "wards_late |float |  Average Ratio of Wards Placed after 20 minutes\n",
    "most_played_champ |string | Most Frequently Played Champion\n",
    "most_played_role |string | Most Frequently Played Role\n",
    "most_played_lane | string| Most Frequently Played Lane\n",
    "role |string | Simplified Most Played Role\n",
    "op_gg | string| URL of player's op.gg account profile\n",
    "similarity|float|Euclidean Distance from Role Model Player to User\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:55:44.369365Z",
     "start_time": "2020-09-08T20:55:42.523274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports and constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import jsonlines\n",
    "import json\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "region_base_url_dict = {'na':'na1.api.riotgames.com',\n",
    "          'br':'br1.api.riotgames.com',\n",
    "          'eun':'eun1.api.riotgames.com',\n",
    "          'euw':'euw1.api.riotgames.com',\n",
    "          'jp':'jp1.api.riotgames.com',\n",
    "          'kr':'kr.api.riotgames.com',\n",
    "          'la1':'la1.api.riotgames.com',\n",
    "          'la2':'la2.api.riotgames.com',\n",
    "          'oce':'oc1.api.riotgames.com',\n",
    "          'tr':'tr1.api.riotgames.com',\n",
    "          'ru':'ru.api.riotgames.com'}\n",
    "            \n",
    "api_key = pd.read_json('../secrets.json')['riot_api_key'][0]\n",
    "\n",
    "timeline_by_match_id_url = '/lol/match/v4/timelines/by-match/'\n",
    "\n",
    "match_by_match_id_url = '/lol/match/v4/matches/'\n",
    "\n",
    "account_by_name_url = '/lol/summoner/v4/summoners/by-name/'\n",
    "\n",
    "match_hist_by_id_url = '/lol/match/v4/matchlists/by-account/'\n",
    "\n",
    "challenger_ladder_url = '/lol/league/v4/challengerleagues/by-queue/RANKED_SOLO_5x5'\n",
    "\n",
    "summoner_by_summoner_id = '/lol/summoner/v4/summoners/'\n",
    "\n",
    "champions = requests.get('http://ddragon.leagueoflegends.com/cdn/10.16.1/data/en_US/champion.json').json()\n",
    "\n",
    "champions_df = pd.DataFrame(champions['data']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the Riot API had some unique challenges. The rate limit for a developer key (the basic level of access) is low, at 100 requests per 2 minutes. To get a large enough pool of players to recommend as Role Models, we split up our requests by the region of each player, as each regional endpoint has its own rate limit. First, we pulled a list of all players in the Challenger division (top ~200 players per server), then used multithreading to request all their matches, with each thread querying a different region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_all_challengers():\n",
    "    challengers_df = pd.DataFrame()\n",
    "    for key, base_url in region_base_url_dict.items():\n",
    "        ladder_response = requests.get(f'https://{base_url}{challenger_ladder_url}?api_key={api_key}')\n",
    "        try:\n",
    "            assert(ladder_response.status_code == 200)\n",
    "            response_df = pd.DataFrame(ladder_response.json()['entries'])\n",
    "            response_df['region'] = [key] * len(response_df)\n",
    "            challengers_df = pd.concat([challengers_df,response_df])\n",
    "        except:\n",
    "            print(f'Bad request for {key}: {ladder_response.status_code}')\n",
    "        time.sleep(1.2001)\n",
    "        \n",
    "    return challengers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T16:04:54.053237Z",
     "start_time": "2020-09-02T16:04:54.047253Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_summoner_by_name(base_url, summoner_name):\n",
    "    return requests.get(f'https://{base_url}{account_by_name_url}{summoner_name}?api_key={api_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T15:56:20.858563Z",
     "start_time": "2020-09-02T15:56:20.853576Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_summoner(base_url, summoner_id):\n",
    "    return requests.get(f'https://{base_url}{summoner_by_summoner_id}{summoner_id}?api_key={api_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T15:56:21.750793Z",
     "start_time": "2020-09-02T15:56:21.746803Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_match_hist(account_id, base_url, queue = '420'):\n",
    "    return requests.get(f'https://{base_url}{match_hist_by_id_url}{account_id}?api_key={api_key}&queue={queue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T15:56:22.854096Z",
     "start_time": "2020-09-02T15:56:22.849109Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_match(match_id, base_url):\n",
    "    return requests.get(f'https://{base_url}{match_by_match_id_url}{match_id}?api_key={api_key}'),requests.get(f'https://{base_url}{timeline_by_match_id_url}{match_id}?api_key={api_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_challenger_match_hists(region, challengers_df = all_challengers, has_account_id=False):\n",
    "    challengers_df = challengers_df[['summonerId','region']]\n",
    "    challengers_df['player_ids'] = [np.nan] * len(challengers_df)\n",
    "    challengers_df = challengers_df[challengers_df['region'] == region]\n",
    "    challengers_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    if has_account_id==False:\n",
    "        for i, tuples in enumerate(challengers_df.values):\n",
    "            if i % 500 == 0:\n",
    "                print(f'{i} of {len(challengers_df)} account ids')\n",
    "            summoner_id, region, unused_pid = tuples\n",
    "            summoner = get_summoner(region_base_url_dict[region],summoner_id).json()\n",
    "            account_id = summoner['accountId']\n",
    "            challengers_df.loc[i,'account_ids'] = account_id\n",
    "            all_challengers.loc[i,'account_ids'] = account_id\n",
    "            time.sleep(1.2)\n",
    "        \n",
    "    challenger_match_hists = pd.DataFrame()\n",
    "    for i, account_id in enumerate(challengers_df['account_ids']):\n",
    "        if i % 500 == 0:\n",
    "            print(f'{i} of {len(challengers_df)} match histories')\n",
    "        try:\n",
    "            match_hist = pd.DataFrame(get_match_hist(account_id, region_base_url_dict[challengers_df.loc[i,'region']]).json()['matches'])\n",
    "            match_hist['region'] = [challengers_df.loc[i,'region']] * len(match_hist)\n",
    "            match_hist['account_id'] = [account_id] * len(match_hist)\n",
    "            challenger_match_hists = pd.concat([challenger_match_hists, match_hist])\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(1.2)\n",
    "    \n",
    "    return challenger_match_hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def scrape_seeds(region):\n",
    "    print(f'{region} thread initialized')\n",
    "    start_time = time.time()\n",
    "    base_url = region_base_url_dict[region]\n",
    "    \n",
    "    matches_list = []\n",
    "    scraped_ids = set()\n",
    "    timelines_list = []\n",
    "    scraped_participants = set()\n",
    "    unscraped_ids = set()\n",
    "    scraped_matches = []\n",
    "    \n",
    "    with jsonlines.open(f'../data/scraped_ids_{region}.jsonl') as infile:\n",
    "        print(f'reading scraped_ids_{region}')\n",
    "        for line in infile.iter():\n",
    "            scraped_ids.add(line)       \n",
    "    \n",
    "    with jsonlines.open(f'../data/unscraped_ids_{region}.jsonl') as infile:\n",
    "            print(f'reading unscraped_ids_{region}')\n",
    "            for line in infile.iter():\n",
    "                unscraped_ids.add(line)\n",
    "                \n",
    "    with jsonlines.open(f'../data/matches_{region}.jsonl') as infile:\n",
    "            print(f'reading matches_{region}')\n",
    "            for line in infile.iter():\n",
    "                scraped_matches.append(dict(line)['gameId'])     \n",
    "    \n",
    "    seed = pd.read_csv('../data/challenger_match_hists_ranked_only.csv')\n",
    "    \n",
    "    seed = seed[seed['region']==region]\n",
    "    \n",
    "    seed.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for i, account_id in enumerate(seed['account_id']):\n",
    "        if account_id not in scraped_ids or seed.loc[i,'gameId'] not in scraped_matches:\n",
    "            scraped_ids.add(account_id)\n",
    "            match, timeline = get_match(seed.loc[i,'gameId'], base_url)\n",
    "        \n",
    "            if match.status_code == 200 and timeline.status_code == 200:\n",
    "                matches_list.append(match.json())\n",
    "                timelines_list.append(timeline.json())\n",
    "                [scraped_participants.add(part['player']['accountId']) for part in match.json()['participantIdentities']]\n",
    "                scraped_matches.append(seed.loc[i,'gameId'])\n",
    "            else:\n",
    "                print(f'matches error: {match.status_code}\\ntimelines error: {timeline.status_code}\\nSummoner: {account_id}\\nRegion:{region}')\n",
    "            time.sleep(2.4)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if 'match' in locals():\n",
    "            if i % 100 == 0 or match.status_code == 403:\n",
    "                print(f'{i} matches scraped of {len(seed)}\\nRegion: {region}\\n')\n",
    "                try:\n",
    "                    with open(f'../data/matches_{region}.jsonl', 'a') as outfile:\n",
    "                        for entry in matches_list:\n",
    "                            json.dump(entry, outfile)\n",
    "                            outfile.write('\\n')\n",
    "                            matches_list = []\n",
    "\n",
    "                    with open(f'../data/timelines_{region}.jsonl', 'a') as outfile:\n",
    "                        for entry in timelines_list:\n",
    "                            json.dump(entry, outfile)\n",
    "                            outfile.write('\\n')\n",
    "                            timelines_list = []\n",
    "\n",
    "                    with open(f'../data/scraped_ids_{region}.jsonl', 'w') as outfile:\n",
    "                        for entry in scraped_ids:\n",
    "                            json.dump(entry, outfile)\n",
    "                            outfile.write('\\n')\n",
    "\n",
    "                    unscraped_ids = unscraped_ids.union(scraped_participants)\n",
    "                    unscraped_ids -= scraped_ids\n",
    "\n",
    "                    with open(f'../data/unscraped_ids_{region}.jsonl', 'w') as outfile:\n",
    "                        for entry in unscraped_ids:\n",
    "                            json.dump(entry, outfile)\n",
    "                            outfile.write('\\n')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                if match.status_code == 403:\n",
    "                    return None\n",
    "            \n",
    "    with open(f'../data/matches_{region}.jsonl', 'a') as outfile:\n",
    "        for entry in matches_list:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    with open(f'../data/timelines_{region}.jsonl', 'a') as outfile:\n",
    "        for entry in timelines_list:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    with open(f'../data/scraped_ids_{region}.jsonl', 'a') as outfile:\n",
    "        for entry in scraped_ids:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    print(f'Seeds scraped, region = {region}')\n",
    "\n",
    "    unscraped_ids = unscraped_ids.union(scraped_participants)\n",
    "    unscraped_ids -= scraped_ids\n",
    "    \n",
    "    with open(f'../data/unscraped_ids_{region}.jsonl', 'w') as outfile:\n",
    "        for entry in unscraped_ids:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T21:56:53.357197Z",
     "start_time": "2020-09-01T21:56:53.348220Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(region):\n",
    "    match_list = []\n",
    "    timeline_list = []\n",
    "    \n",
    "    with jsonlines.open(f'../data/matches_{region}.jsonl') as infile:\n",
    "                for line in infile.iter():\n",
    "                    match_list.append(line) \n",
    "                    \n",
    "    with jsonlines.open(f'../data/timelines_{region}.jsonl') as infile:\n",
    "            for line in infile.iter():\n",
    "                    timeline_list.append(line)\n",
    "    \n",
    "    del infile\n",
    "    ranked_matches = []\n",
    "    ranked_timelines = []\n",
    "    is_ranked = []\n",
    "    game_ids = set()\n",
    "    \n",
    "    for i, match in enumerate(match_list):\n",
    "        if match['queueId'] == 420 and match['gameId'] not in game_ids:\n",
    "            ranked_matches.append(match)\n",
    "            is_ranked.append(i)\n",
    "            game_ids.add(match['gameId'])\n",
    "    del match_list\n",
    "    \n",
    "    \n",
    "    with open(f'../data/cleaned/matches_{region}.jsonl', 'w') as outfile:\n",
    "        for entry in ranked_matches:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "    del ranked_matches\n",
    "    \n",
    "    \n",
    "    for i, timeline in enumerate(timeline_list):\n",
    "        if i in is_ranked:\n",
    "            ranked_timelines.append(timeline)\n",
    "    del timeline_list\n",
    "            \n",
    "    \n",
    "\n",
    "    with open(f'../data/cleaned/timelines_{region}.jsonl', 'w') as outfile:\n",
    "        for entry in ranked_timelines:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')   \n",
    "    del ranked_timelines\n",
    "    del is_ranked\n",
    "    del game_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T21:56:54.452062Z",
     "start_time": "2020-09-01T21:56:54.442090Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def remove_short_games(region):\n",
    "    match_list = []\n",
    "    timeline_list = []\n",
    "    \n",
    "    with jsonlines.open(f'../data/cleaned/matches_{region}.jsonl') as infile:\n",
    "                for line in infile.iter():\n",
    "                    match_list.append(line) \n",
    "    del infile\n",
    "                 \n",
    "    with jsonlines.open(f'../data/cleaned/timelines_{region}.jsonl') as infile:\n",
    "                for line in infile.iter():\n",
    "                    timeline_list.append(line) \n",
    "    del infile\n",
    "                    \n",
    "    good_matches = []\n",
    "    good_timelines = []\n",
    "    valid = []\n",
    "    game_ids = set()\n",
    "    \n",
    "    for i, match in enumerate(match_list):\n",
    "        if match['gameDuration'] / 60 > 15 and match['gameId'] not in game_ids:\n",
    "            add = True\n",
    "            # Remove games where a player didn't reach level 6 (based on EDA)\n",
    "            for participant in match['participants']:\n",
    "                if participant['stats']['champLevel'] < 7:\n",
    "                    add = False\n",
    "            if add:\n",
    "                good_matches.append(match)\n",
    "                valid.append(i)\n",
    "                game_ids.add(match['gameId'])\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    del match_list\n",
    "  \n",
    "    with open(f'../data/cleaned/matches_{region}.jsonl', 'w') as outfile:\n",
    "        for entry in good_matches:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "    del good_matches\n",
    "    \n",
    "    for i, timeline in enumerate(timeline_list):\n",
    "        if i in valid:\n",
    "            good_timelines.append(timeline)\n",
    "    \n",
    "    del timeline_list\n",
    "            \n",
    "    \n",
    "\n",
    "    with open(f'../data/cleaned/timelines_{region}.jsonl', 'w') as outfile:\n",
    "        for entry in good_timelines:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "            \n",
    "    del good_timelines\n",
    "    del valid\n",
    "    del game_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling all Challenger players' match histories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_challengers = get_all_challengers()\n",
    "\n",
    "all_challengers.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_hist_list = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 11) as executor:\n",
    "    for result in executor.map(get_challenger_match_hists, region_base_url_dict.keys()):\n",
    "        match_hist_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_match_hists = pd.concat(match_hist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_match_hists.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_match_hists.to_csv('../data/challenger_match_hists_ranked_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading match and timeline data for all challenger match histories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 11) as executor:\n",
    "    executor.map(scrape_seeds, region_base_url_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally removing all duplicate games and games which lasted less than 15 minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_base_url_dict.keys():\n",
    "    remove_duplicates(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_base_url_dict.keys():\n",
    "    remove_short_games(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T16:21:31.847509Z",
     "start_time": "2020-09-02T16:21:31.791680Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_stats(summoner, region, matches, timelines, team_participants = ([1,2,3,4,5],[6,7,8,9,10])):\n",
    "# For each player:\n",
    "    output = pd.DataFrame(columns=['champ_played', 'role','lane', 'csd_10',\n",
    "                                  'gold_d_10','xpd_10','dmg_share','dmg_taken_share','vision_score',\n",
    "                                  'kill_participation','obj_dmg_share','dragons','barons','wards_cleared',\n",
    "                                  'vision_wards_purchased','kda_early', 'kda_mid', 'kda_late', \n",
    "                                   'solo_kills', 'teamfight_kills', 'skirmish_kills', 'wards_early', \n",
    "                                   'wards_mid', 'wards_late'])\n",
    "    # Main role = most played role where role is played > 40% of the time\n",
    "    # Main champion = most played champion\n",
    "    # Select all matches and timelines that they are in\n",
    "    for i, match in enumerate(matches):\n",
    "        is_in_game = summoner in [summoner['player']['summonerId'] for summoner in match['participantIdentities']]\n",
    "        if is_in_game:\n",
    "        # For each match:\n",
    "        # Match info:\n",
    "            game_id = match['gameId']\n",
    "            player_id = int([player['participantId'] for player in match['participantIdentities'] if player['player']['summonerId'] == summoner][0]) - 1\n",
    "            player_name = match['participantIdentities'][player_id]['player']['summonerName']\n",
    "            \n",
    "            # Identify champion played\n",
    "            champ_played = match['participants'][player_id]['championId']\n",
    "            \n",
    "            # Identify role played\n",
    "            role = match['participants'][player_id]['timeline']['role']\n",
    "            lane = match['participants'][player_id]['timeline']['lane']\n",
    "            # Identify lane opponent\n",
    "            team = match['participants'][player_id]['teamId']\n",
    "            team_index = int(str(team)[0]) - 1\n",
    "            teammates = team_participants[team_index]\n",
    "               \n",
    "            # Get CSD, GoldD and XPD @ 10\n",
    "            csd_10 = match['participants'][player_id]['timeline']['creepsPerMinDeltas']['0-10']\n",
    "            gold_d_10 = match['participants'][player_id]['timeline']['goldPerMinDeltas']['0-10']\n",
    "            xpd_10 = match['participants'][player_id]['timeline']['xpPerMinDeltas']['0-10']\n",
    "            \n",
    "            # Get DMG share\n",
    "            total_dmg = np.sum([player['stats']['totalDamageDealtToChampions'] for player in match['participants'] if player['teamId'] == team])\n",
    "            dmg_share = match['participants'][player_id]['stats']['totalDamageDealtToChampions'] / total_dmg\n",
    "            \n",
    "            # Get DMG Taken share\n",
    "            total_dmg_taken = np.sum([player['stats']['totalDamageTaken'] for player in match['participants'] if player['teamId'] == team])\n",
    "            dmg_taken_share = match['participants'][player_id]['stats']['totalDamageTaken'] / total_dmg_taken\n",
    "            \n",
    "            # Get vision score\n",
    "            vision_score = match['participants'][player_id]['stats']['visionScore']\n",
    "            \n",
    "            # Get overall kill participation\n",
    "            team_kills = np.sum([player['stats']['kills'] for player in match['participants'] if player['participantId'] in teammates]) + 1\n",
    "            kill_participation = (match['participants'][player_id]['stats']['kills'] + match['participants'][player_id]['stats']['assists']) / team_kills\n",
    "            \n",
    "            # % of team's objective damage % of team's turret damage\n",
    "            total_obj_dmg = np.sum([player['stats']['damageDealtToObjectives'] for player in match['participants'] if player['teamId'] == team])\n",
    "            obj_dmg_share = match['participants'][player_id]['stats']['damageDealtToObjectives'] / total_obj_dmg\n",
    "            \n",
    "            # Team % of dragons killed\n",
    "            team_dragons = match['teams'][team_index]['dragonKills']\n",
    "            total_dragons = team_dragons + match['teams'][0 if team_index == 1 else 1]['dragonKills']\n",
    "            dragons = team_dragons / (total_dragons + 1)\n",
    "            \n",
    "            # Team % of barons killed\n",
    "            team_barons = match['teams'][team_index]['baronKills']\n",
    "            total_barons = team_barons + match['teams'][0 if team_index == 1 else 1]['baronKills']\n",
    "            barons = team_barons / (total_barons + 1)\n",
    "            \n",
    "            # Get wards cleared\n",
    "            wards_cleared = match['participants'][player_id]['stats']['wardsKilled']\n",
    "            \n",
    "            # Get pinks purchased\n",
    "            vision_wards_purchased = match['participants'][player_id]['stats']['visionWardsBoughtInGame']\n",
    "            \n",
    "            # For each timeline:\n",
    "            timeline = timelines[i]\n",
    "            \n",
    "            kills = 0\n",
    "            kda = 0\n",
    "            kda_early = 0\n",
    "            kda_mid = 0\n",
    "            kda_late = 0\n",
    "            solo_kills = 0\n",
    "            teamfight_kills = 0\n",
    "            skirmish_kills = 0\n",
    "            wards = 0\n",
    "            wards_early = 0\n",
    "            wards_mid = 0\n",
    "            wards_late = 0\n",
    "            \n",
    "            for i, frame in enumerate(timeline['frames']):\n",
    "                for event in frame['events']:\n",
    "                    # Get 0-10 K+D+A\n",
    "                    # Get 10-20 K+D+A\n",
    "                    # Get 20+ K+D+A\n",
    "                    if event['type'] == 'CHAMPION_KILL':\n",
    "                        if (player_id + 1) == event['killerId'] or (player_id + 1) == event['victimId'] or (player_id + 1) in event['assistingParticipantIds']:\n",
    "                            kda += 1\n",
    "                            if i < 12:\n",
    "                                kda_early += 1\n",
    "                            elif i < 22:\n",
    "                                kda_mid += 1\n",
    "                            else:\n",
    "                                kda_late += 1\n",
    "\n",
    "                        if (player_id + 1) == event['killerId']:\n",
    "                            kills += 1\n",
    "                    # get number of solo kills\n",
    "                    # get number of skirmish kills\n",
    "                    # get number of teamfight kills\n",
    "                            if event['assistingParticipantIds'] == []:\n",
    "                                solo_kills += 1\n",
    "                            if len(event['assistingParticipantIds']) == 1:\n",
    "                                skirmish_kills += 1\n",
    "                            if  len(event['assistingParticipantIds']) > 1:\n",
    "                                teamfight_kills += 1\n",
    "                    # Get 0-10 wards placed\n",
    "                    # Get 10-20 wards placed\n",
    "                    # Get 20+ wards placed\n",
    "                    if event['type'] == 'WARD_PLACED' and (player_id + 1) == event['creatorId']:\n",
    "                        wards += 1\n",
    "                        if i < 12:\n",
    "                            wards_early += 1\n",
    "                        elif i < 22:\n",
    "                            wards_mid += 1\n",
    "                        else:\n",
    "                            wards_late += 1 \n",
    "            \n",
    "            solo_kills /= kills + 1\n",
    "            skirmish_kills /= kills + 1\n",
    "            teamfight_kills /= kills + 1\n",
    "            wards_early /= wards + 1\n",
    "            wards_mid /= wards + 1\n",
    "            wards_late /= wards + 1 \n",
    "            kda_early /= kda + 1\n",
    "            kda_mid /= kda + 1\n",
    "            kda_late /= kda + 1\n",
    "            \n",
    "            # Wards cleared and vision wards purchased as a % of wards placed\n",
    "            wards_cleared /= wards + 1\n",
    "            vision_wards_purchased /= wards + 1\n",
    "            \n",
    "            output = output.append({'champ_played':champ_played, 'role':role, 'lane':lane,\n",
    "             'csd_10':csd_10,'gold_d_10':gold_d_10,'xpd_10':xpd_10,'dmg_share':dmg_share,\n",
    "             'dmg_taken_share':dmg_taken_share,'vision_score':vision_score,\n",
    "             'kill_participation':kill_participation,'obj_dmg_share':obj_dmg_share,'dragons':dragons,\n",
    "             'barons':barons,'wards_cleared':wards_cleared,'vision_wards_purchased':vision_wards_purchased,\n",
    "             'kda_early':kda_early, 'kda_mid':kda_mid, 'kda_late':kda_late, 'solo_kills':solo_kills, \n",
    "             'teamfight_kills':teamfight_kills, 'skirmish_kills':skirmish_kills, 'wards_early':wards_early, \n",
    "             'wards_mid':wards_mid, 'wards_late':wards_late}, ignore_index=True)\n",
    "    \n",
    "    most_played_champ = output['champ_played'].value_counts().index[0]\n",
    "    most_played_role = output['role'].value_counts().index[0]\n",
    "    most_played_lane = output['lane'].value_counts().index[0]\n",
    "    \n",
    "    output.drop(columns=['champ_played','role','lane'], inplace=True)\n",
    "\n",
    "    output = pd.DataFrame(output.mean()).transpose()\n",
    "    output['summoner_id'] = [summoner]\n",
    "    output['most_played_champ'] = most_played_champ\n",
    "    output['most_played_role'] = most_played_role\n",
    "    output['most_played_lane'] = most_played_lane\n",
    "    output['region'] = region\n",
    "    output['player_name'] = player_name\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and User Feedback\n",
    "\"Personally, I found the champion stuff the most interesting part of the data, especially identifying trends across multiple players. I feel like the whole thing gave me some interesting ideas and allowed me to look at the way I play in a different way.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Riot Games API](https://developer.riotgames.com/apis)\n",
    "- [How Well does Personalized Marketing Work?](https://knowledge.wharton.upenn.edu/article/recommended-for-you-how-well-does-personalized-marketing-work/)\n",
    "- [Recommender Systems in Python 101](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101)\n",
    "- [Building the Next New York Times Recommendation Engine](https://open.blogs.nytimes.com/2015/08/11/building-the-next-new-york-times-recommendation-engine)\n",
    "- [The Netflix Recommender System: Algorithms, Business Value, and Innovation](https://dl.acm.org/doi/10.1145/2843948)\n",
    "- [How Machine Learning Fuels Your Netflix Addiction](https://www.rtinsights.com/netflix-recommendations-machine-learning-algorithms/)\n",
    "- [The Treasure Chest of League of Legends: Riotâ€™s APIs](https://medium.com/@montane/the-treasure-chest-of-league-of-legends-riots-apis-64816f4d3f84)\n",
    "- [Part 1 of Riot API: Data Downpour](https://towardsdatascience.com/data-downpour-b1c4b41d7862)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
